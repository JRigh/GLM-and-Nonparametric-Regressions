{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C3M1: Peer Reviewed Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline:\n",
    "The objectives for this assignment:\n",
    "\n",
    "1. Apply Binomial regression methods to real data.\n",
    "2. Understand how to analyze and interpret binomial regression models.\n",
    "3. Flex our math skills by determining whether certain distributions are members of the exponential family.\n",
    "\n",
    "General tips:\n",
    "\n",
    "1. Read the questions carefully to understand what is being asked.\n",
    "2. This work will be reviewed by another human, so make sure that you are clear and concise in what your explanations and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.0     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.2.1     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries\n",
    "library(tidyverse)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Binomial (Logistic) Regression\n",
    "\n",
    "The National Institute of Diabetes and Digestive and Kidney Diseases conducted a study of 768 adult female Pima Indians living near Phoenix, AZ. The purpose of the study was to investigate the factors related to diabetes. \n",
    "\n",
    "*Before we analyze these data, we should note that some have raised ethical issues with its collection and popularity in the statistics and data science community. We should think seriously about these concerns. For example, Maya Iskandarani wrote a brief [piece](https://researchblog.duke.edu/2016/10/24/diabetes-and-privacy-meet-big-data/) on consent and privacy concerns raised by this dataset. After you familarize yourself with the data, we'll then turn to these ethical concerns.*\n",
    "\n",
    "\n",
    "First, we'll use these data to get some practice with GLM and Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>pregnant</th><th scope=col>glucose</th><th scope=col>diastolic</th><th scope=col>triceps</th><th scope=col>insulin</th><th scope=col>bmi</th><th scope=col>diabetes</th><th scope=col>age</th><th scope=col>test</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>6</td><td>148</td><td>72</td><td>35</td><td>  0</td><td>33.6</td><td>0.627</td><td>50</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td> 85</td><td>66</td><td>29</td><td>  0</td><td>26.6</td><td>0.351</td><td>31</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>8</td><td>183</td><td>64</td><td> 0</td><td>  0</td><td>23.3</td><td>0.672</td><td>32</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td> 89</td><td>66</td><td>23</td><td> 94</td><td>28.1</td><td>0.167</td><td>21</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0</td><td>137</td><td>40</td><td>35</td><td>168</td><td>43.1</td><td>2.288</td><td>33</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>5</td><td>116</td><td>74</td><td> 0</td><td>  0</td><td>25.6</td><td>0.201</td><td>30</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & pregnant & glucose & diastolic & triceps & insulin & bmi & diabetes & age & test\\\\\n",
       "  & <int> & <int> & <int> & <int> & <int> & <dbl> & <dbl> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 6 & 148 & 72 & 35 &   0 & 33.6 & 0.627 & 50 & 1\\\\\n",
       "\t2 & 1 &  85 & 66 & 29 &   0 & 26.6 & 0.351 & 31 & 0\\\\\n",
       "\t3 & 8 & 183 & 64 &  0 &   0 & 23.3 & 0.672 & 32 & 1\\\\\n",
       "\t4 & 1 &  89 & 66 & 23 &  94 & 28.1 & 0.167 & 21 & 0\\\\\n",
       "\t5 & 0 & 137 & 40 & 35 & 168 & 43.1 & 2.288 & 33 & 1\\\\\n",
       "\t6 & 5 & 116 & 74 &  0 &   0 & 25.6 & 0.201 & 30 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| <!--/--> | pregnant &lt;int&gt; | glucose &lt;int&gt; | diastolic &lt;int&gt; | triceps &lt;int&gt; | insulin &lt;int&gt; | bmi &lt;dbl&gt; | diabetes &lt;dbl&gt; | age &lt;int&gt; | test &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 6 | 148 | 72 | 35 |   0 | 33.6 | 0.627 | 50 | 1 |\n",
       "| 2 | 1 |  85 | 66 | 29 |   0 | 26.6 | 0.351 | 31 | 0 |\n",
       "| 3 | 8 | 183 | 64 |  0 |   0 | 23.3 | 0.672 | 32 | 1 |\n",
       "| 4 | 1 |  89 | 66 | 23 |  94 | 28.1 | 0.167 | 21 | 0 |\n",
       "| 5 | 0 | 137 | 40 | 35 | 168 | 43.1 | 2.288 | 33 | 1 |\n",
       "| 6 | 5 | 116 | 74 |  0 |   0 | 25.6 | 0.201 | 30 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  pregnant glucose diastolic triceps insulin bmi  diabetes age test\n",
       "1 6        148     72        35        0     33.6 0.627    50  1   \n",
       "2 1         85     66        29        0     26.6 0.351    31  0   \n",
       "3 8        183     64         0        0     23.3 0.672    32  1   \n",
       "4 1         89     66        23       94     28.1 0.167    21  0   \n",
       "5 0        137     40        35      168     43.1 2.288    33  1   \n",
       "6 5        116     74         0        0     25.6 0.201    30  0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "pima = read.csv(\"pima.txt\", sep=\"\\t\")\n",
    "# Here's a description of the data: https://rdrr.io/cran/faraway/man/pima.html\n",
    "head(pima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (a) Data Cleaning? What about Data Scrubbing? Data Sterilizing?\n",
    "\n",
    "This is a real data set, which means that there's likely going to be gaps and missing values in the data. Before doing any modeling, we should inspect the data and clean it if necesary.\n",
    "\n",
    "Perform simple graphical and numerical summaries of the data. Pay attention for missing or nonsensical values. Can you find any obvious irregularities? If so, take appropriate steps to correct these problems. In the markdown cell, specify what cleaning you did and why you did it.\n",
    "\n",
    "Finally, split your data into training and test sets. Let the training set contain $80\\%$ of the rows and the test set contain the remaining $20\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pregnant   glucose diastolic   triceps   insulin       bmi  diabetes       age \n",
      "        0         0         0         0         0         0         0         0 \n",
      "     test \n",
      "        0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    pregnant         glucose        diastolic         triceps     \n",
       " Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  \n",
       " 1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  \n",
       " Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  \n",
       " Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  \n",
       " 3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  \n",
       " Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  \n",
       "    insulin           bmi           diabetes           age       \n",
       " Min.   :  0.0   Min.   : 0.00   Min.   :0.0780   Min.   :21.00  \n",
       " 1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437   1st Qu.:24.00  \n",
       " Median : 30.5   Median :32.00   Median :0.3725   Median :29.00  \n",
       " Mean   : 79.8   Mean   :31.99   Mean   :0.4719   Mean   :33.24  \n",
       " 3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262   3rd Qu.:41.00  \n",
       " Max.   :846.0   Max.   :67.10   Max.   :2.4200   Max.   :81.00  \n",
       "      test      \n",
       " Min.   :0.000  \n",
       " 1st Qu.:0.000  \n",
       " Median :0.000  \n",
       " Mean   :0.349  \n",
       " 3rd Qu.:1.000  \n",
       " Max.   :1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 614 \n",
      "Testing data size: 154 \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check for missing values\n",
    "missing_summary <- sapply(pima, function(x) sum(is.na(x)))\n",
    "print(missing_summary)\n",
    "\n",
    "# Step 4: Impute missing values (use mean imputation as an example)\n",
    "pima_clean <- pima\n",
    "for (col in names(pima_clean)) {\n",
    "  if (is.numeric(pima_clean[[col]])) {\n",
    "    pima_clean[[col]][is.na(pima_clean[[col]])] <- mean(pima_clean[[col]], na.rm = TRUE)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Step 5: Summary of cleaned data\n",
    "summary(pima_clean)\n",
    "\n",
    "# Step 6: Split the data into train (80%) and test (20%)\n",
    "set.seed(2024) # Set seed for reproducibility\n",
    "train_indices <- sample(1:nrow(pima_clean), size = 0.8 * nrow(pima_clean))\n",
    "train_data <- pima_clean[train_indices, ]\n",
    "test_data <- pima_clean[-train_indices, ]\n",
    "\n",
    "# Verify the split\n",
    "cat(\"Training data size:\", nrow(train_data), \"\\n\")\n",
    "cat(\"Testing data size:\", nrow(test_data), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (b) Initial GLM modelling\n",
    "\n",
    "\n",
    "Our data is clean and we're ready to fit! What kind of model should we use to fit these data? Notice that the `test` variable is either $0$ or $1$, for whether the individual tested positive for diabetes. Because `test` is binary, we should use logistic regression (which is a kind of binomial regression).\n",
    "\n",
    "Fit a model with `test` as the response and all the other variables as predictors. Can you tell whether this model fits the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = test ~ ., family = binomial, data = train_data)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4798  -0.7300  -0.4281   0.7420   2.9493  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -8.2130001  0.7785903 -10.549  < 2e-16 ***\n",
       "pregnant     0.1183929  0.0357879   3.308 0.000939 ***\n",
       "glucose      0.0352638  0.0041847   8.427  < 2e-16 ***\n",
       "diastolic   -0.0130875  0.0057262  -2.286 0.022281 *  \n",
       "triceps     -0.0009585  0.0075277  -0.127 0.898678    \n",
       "insulin     -0.0009091  0.0009840  -0.924 0.355526    \n",
       "bmi          0.0860673  0.0166329   5.175 2.29e-07 ***\n",
       "diabetes     0.7810790  0.3211506   2.432 0.015010 *  \n",
       "age          0.0152288  0.0102926   1.480 0.138982    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 796.42  on 613  degrees of freedom\n",
       "Residual deviance: 583.55  on 605  degrees of freedom\n",
       "AIC: 601.55\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Actual\n",
      "Predicted  0  1\n",
      "        0 92 22\n",
      "        1 10 30\n",
      "Accuracy: 0.7922078 \n"
     ]
    }
   ],
   "source": [
    "# logit model\n",
    "logit_model <- glm(test ~ ., data = train_data, family = binomial)\n",
    "\n",
    "# summarize the model fit\n",
    "summary(logit_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (c) Remember Bayes\n",
    "\n",
    "A quick analytical interlude.\n",
    "\n",
    "Is diastolic blood pressure significant in the regression model? Do women who test positive have higher diastolic blood pressures? Explain the distinction between the two questions and discuss why the answers are only apparently contradictory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first question is about significance and the p-value appear to be lower than 0.05. \n",
    "# The second question is about the effect which would be higher for women than men. \n",
    "# There might be some correlated variable producing this effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (d) GLM Interpretation\n",
    "\n",
    "We've seen so many regression summaries up to this point, how is this one different from all the others? Well, to really understand any model, it can be helpful to loop back and plug the fitted results back into the model's mathematical form.\n",
    "\n",
    "Explicity write out the equation for the binomial regression model that you fit in (b). Then, in words, explain how a $1$ unit change of `glucose` affects `test`, assuming all other predictors are held constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test =−8.213+0.118⋅pregnant+0.035⋅glucose−0.013⋅diastolic−0.001⋅triceps−0.001⋅insulin+0.086⋅bmi+0.781⋅diabetes+0.015⋅age\n",
    "# The coefficient for glucose is 0.0350.035, meaning:\n",
    "# For a 1-unit increase in glucose, holding all other predictors constant, the log-odds of testing positive (test=1test=1) increase by 0.0350.035.\n",
    "# In terms of probabilities, a 1-unit increase in glucose increases the odds of testing positive by a factor of exp⁡(0.035)≈1.036exp(0.035)≈1.036, or about 3.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (e) GLM Prediction\n",
    "\n",
    "One of the downsides of Logistic Regression is that there isn't an easy way of evaulating the goodness of fit of the model without predicting on new data. But, if we have more data to test with, then there are many methods of evaluation to use. One of the best tools are confusion matrices, which (despite the name) are actually not that hard to understand.\n",
    "\n",
    "A confusion matrix compares the predicted outcomes of a Logistic Regression Model (or any classification model) with the actual classifications. For binary classification, it is a $2 \\times 2$ matrix where the rows are the models' predicted outcome and the columns are the actual classifications. An example is displayed below.\n",
    "\n",
    "|  | True | False |  \n",
    "| --- | --- | --- |\n",
    "| 1 | 103 | 37 |  \n",
    "| 0 | 55  | 64 |  \n",
    "\n",
    "In the example, we know the following information:\n",
    "* The [1,1] cell is the number of datapoints that were correctly predicted to be $1$. The value (103) is the number of True Positives (TP). \n",
    "* The [2,2] cell is the number of datapoints that were correctly predicted to be $0$. The value is the number of True Negatives (TN).\n",
    "* The [1, 2] cell is the number of datapoints that were predicted to be $1$ but where actually $0$. This is the number of False Positives (FP), also called Type I error. In the context of our diabetes dataset, this would mean our model predicted that the person would have diabetes, but they actually did not.\n",
    "* The [2, 1] cell is the number of datapoints that were predicted to be $0$ but where actually $1$. This is the number of False Negatives (FN), also called Type 2 error. In the context of our diabetes dataset, this would mean our model predicted that the person would not have diabetes, but they actually did have diabetes.\n",
    "\n",
    "Use your model to predict the outcomes of the test set. Then construct a confusion matrix for these predictions and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Actual\n",
      "Predicted  0  1\n",
      "        0 92 22\n",
      "        1 10 30\n",
      "Accuracy: 0.7922078 \n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "predicted_probabilities <- predict(logit_model, newdata = test_data, type = \"response\")\n",
    "predicted_classes <- ifelse(predicted_probabilities > 0.5, 1, 0)\n",
    "\n",
    "# assess the fit using confusion matrix\n",
    "confusion_matrix <- table(Predicted = predicted_classes, Actual = test_data$test)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (f) Evaluation Statistics\n",
    "\n",
    "Using the four values from the confusion matrix, we can construct evaulation statistics to get a numerical approximation for our model's performance. Spend some time researching accuracy, precision, recall and F score. \n",
    "\n",
    "Calculate these values for your model's predictions on the test set. Clearly display your results. How well do you think your model fits the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7922078 \n",
      "Precision: 0.75 \n",
      "Recall: 0.5769231 \n",
      "F1-Score: 0.6521739 \n"
     ]
    }
   ],
   "source": [
    "# calculate metrics like accuracy\n",
    "accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)\n",
    "cat(\"Accuracy:\", accuracy, \"\\n\")\n",
    "\n",
    "# Extract components of the confusion matrix\n",
    "TP <- confusion_matrix[\"1\", \"1\"]  # True Positives\n",
    "FP <- confusion_matrix[\"1\", \"0\"]  # False Positives\n",
    "FN <- confusion_matrix[\"0\", \"1\"]  # False Negatives\n",
    "TN <- confusion_matrix[\"0\", \"0\"]  # True Negatives\n",
    "\n",
    "# Compute Precision\n",
    "precision <- TP / (TP + FP)\n",
    "\n",
    "# Compute Recall\n",
    "recall <- TP / (TP + FN)\n",
    "\n",
    "# Compute F1-Score\n",
    "f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Print results\n",
    "cat(\"Precision:\", precision, \"\\n\")\n",
    "cat(\"Recall:\", recall, \"\\n\")\n",
    "cat(\"F1-Score:\", f1_score, \"\\n\")\n",
    "\n",
    "# The model achieves good precision (0.75), indicating it makes relatively few false positive predictions, \n",
    "# but recall is lower (0.5769), reflecting some missed positive cases, resulting in a moderate F1-score of 0.6522, \n",
    "# balancing precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (g) Understanding Evaluation Statistics\n",
    "\n",
    "Answer the following questions in the markdown cell below.\n",
    "\n",
    "1. Give an example scenario for when accuracy would be a misleading evaulation statistic.\n",
    "2. Confusion matrices can also be used for non-binary classification problems. Describe what a confusion matrix would look like for a response with $3$ levels.\n",
    "3. You'll have to take our word on the fact (or spend some time researching) that Type I error and Type II error are inversely related. That is, if a model is very good at detecting false positives, then it will be bad at detecting false negatives. In the case of our diabetes dataset, would you prefer a model that overestimates the Type 1 error or overestimates the Type II error. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Example Scenario for Misleading Accuracy:\n",
    "\n",
    "Accuracy can be misleading in scenarios with imbalanced datasets. For example, in a medical diagnosis where 95% of patients are healthy, a model that always predicts \"healthy\" achieves 95% accuracy but fails to identify any sick patients.\n",
    "2. Confusion Matrix for 3 Levels:\n",
    "\n",
    "For a response with 3 levels (e.g., A, B, C), a confusion matrix would be a 3x3 table where rows represent the predicted class, and columns represent the actual class. Each cell (i,j)(i,j) shows the number of instances predicted as class ii when the true class is jj.\n",
    "3. Type I vs. Type II Error Preference:\n",
    "\n",
    "In the diabetes dataset, it is preferable to overestimate Type I error (false positives) because detecting diabetes early (even if some healthy individuals are flagged) is critical for timely intervention, whereas missing true cases (Type II error) could lead to severe health consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (h) Ethical Issues in Data Collection\n",
    "\n",
    "Read Maya Iskandarani's [piece](https://researchblog.duke.edu/2016/10/24/diabetes-and-privacy-meet-big-data/) on consent and privacy concerns raised by this dataset. Summarize those concerns here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main concern raised is the ethical dilemma of using historical medical data, such as the Pima Indian Diabetes Data set, which was collected decades ago without consent for future uses, raising issues of privacy, informed consent, and the evolving nature of medical research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Practicing those Math skills\n",
    "\n",
    "One of the conditions of GLMs is that the \"random component\" of the data needs to come from the Exponential Family of Distributions. But how do we know if a distribution is in the Exponential Family? Well, we could look it up. Or we could be proper mathematicians and check the answer ourselves! Let's flex those math muscles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (a) But it's in the name...\n",
    "\n",
    "Show that $Y \\sim exponential(\\lambda)$, where $\\lambda$ is known, is a member of the exponential family."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pdf can be written in the exponential family form as f(y;λ)=exp(log(λ)−λy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (b) Why can't plants do math? Because it gives them square roots!\n",
    "\n",
    "Let $Y_i \\sim exponential(\\lambda)$ where $i \\in \\{ 1, \\dots, n\\}$. Then $Z = \\sum_{i=1}^n Y_i \\sim Gamma(n, \\lambda)$. Show that $Z$ is also a member of the exponential family."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pdf can also be written in the exponential family form, here as: f(z;n,λ)=(n−1)!λnzn−1exp(−λz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
